---
title: "2-Evaluation Methods"
output: 
  html_document:
    keep_md: True
---

Once you have a forecast method, do the following:

1- Make sure your forecast methods **has exploited all the available information in the series in a reasonable manner**. To do so, compare the fitted values for the series and the observations, then, check the difference between them, which we call the residuals. Specially, you will want your residuals to:

- Not be autocorrelated.
- Have a zero mean.
- Have a constant variance.
- Close to normal.

The first three amount to the **residuals being White Noise**. Incorporating the fourth one results in Gaussian White Noise. 

2- Create a reasonable estimation of your forecasting error. To do so, use a training/test separation or use a Cross Validation strategy. Nota bene: use the split with the step-ahead number that is of interest to you, not just the default of one-step ahead prediction. 

# Code

## Checking residuals

```{r}
library(fpp2)
library(forecast)
# Check the residuals from the naive forecasts applied to the goog series
goog %>% naive() %>% checkresiduals()

# Do they look like white noise (TRUE or FALSE)
googwn <- TRUE

# Check the residuals from the seasonal naive forecasts applied to the ausbeer series
ausbeer %>% snaive() %>% checkresiduals

# Do they look like white noise (TRUE or FALSE)
beerwn <- FALSE
```

## Train and test splits


```{r}
# Create the training data as train
train <- window(gold, end = 1000)

# Compute naive forecasts and save to naive_fc
naive_fc <- naive(train, h = length(gold) - length(train))

# Compute mean forecasts and save to mean_fc
mean_fc <- meanf(train, h = 108)

# Use accuracy() to compute RMSE statistics
accuracy(naive_fc, gold)
accuracy(mean_fc, gold)

# Assign one of the two forecasts as bestforecasts
bestforecasts <- naive_fc
```


Here, you will use the Melbourne quarterly visitor numbers (vn[, "Melbourne"]) to create three different training sets, omitting the last 1, 2 and 3 years, respectively. 


## Cross Validation

Here, you will use `tsCV()` to compute and plot the MSE values for up to 8 steps ahead, along with the `naive()` method applied to the goog data.

```{r}
# Compute cross-validated errors for up to 8 steps ahead
e <- as.matrix(tsCV(goog, forecastfunction = naive, h = 8))

# Compute the MSE values and remove missing values
mse <- colMeans(e^2, na.rm = TRUE)

# Plot the MSE values against the forecast horizon
data.frame(h = 1:8, MSE = mse) %>%
  ggplot(aes(x = h, y = MSE)) + geom_point()
```

As we try to forecast ahead, our forecast error incrases. 

## Good Forecast Model

Where possible, try to find a model that has low RMSE on a test set and has white noise residuals



